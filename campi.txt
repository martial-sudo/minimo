#!/usr/bin/env python3
import logging
import threading
import time
import numpy as np
import os
import cv2
import mediapipe as mp
from datetime import datetime
from picamera2 import Picamera2
from libcamera import controls

logger = logging.getLogger(__name__)

class CameraManager:
    def __init__(self, resolution=(640, 480), rotation=0):
        """
        Initialize Camera Manager with Raspberry Pi camera capabilities using MediaPipe.
        
        Args:
            resolution: Tuple of (width, height) for camera resolution
            rotation: Camera rotation in degrees (0, 90, 180, or 270)
        """
        logger.info("Initializing Camera Manager with Pi Camera")
        self.resolution = resolution
        self.rotation = rotation
        self.capturing = False
        self.camera_thread = None
        self.frame_lock = threading.Lock()
        self.current_frame = None
        self.last_frame = None  # For motion detection
        self.last_frame_time = None
        self.security_mode = False
        self.motion_threshold = 30  # Threshold for motion detection
        self.recordings_dir = "security_recordings"
        self.video_writer = None
        self.recording_active = False
        self.recording_start_time = None
        self.picam = None
        
        # Create recordings directory if it doesn't exist
        if not os.path.exists(self.recordings_dir):
            os.makedirs(self.recordings_dir)
        
        # Load face recognition model
        self.load_face_models()
        
    def load_face_models(self):
        """Load MediaPipe face detection and mesh models"""
        logger.info("Loading MediaPipe face detection models")
        
        # Initialize MediaPipe Face Detection
        self.mp_face_detection = mp.solutions.face_detection
        self.face_detection = self.mp_face_detection.FaceDetection(
            min_detection_confidence=0.5,
            model_selection=1  # 0 for short-range, 1 for full-range detection
        )
        
        # Optional: Initialize MediaPipe Face Mesh for more detailed face analysis
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            static_image_mode=False,
            max_num_faces=3,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )
        
        # For drawing utilities
        self.mp_drawing = mp.solutions.drawing_utils
        
        logger.info("MediaPipe face models loaded")
    
    def _initialize_picamera(self):
        """Initialize the Pi Camera with current settings"""
        try:
            # Initialize the camera
            self.picam = Picamera2()
            
            # Configure the camera
            config = self.picam.create_preview_configuration(
                main={"size": self.resolution, "format": "RGB888"},
                buffer_count=2
            )
            self.picam.configure(config)
            
            # Set controls
            self.picam.set_controls({
                "AwbEnable": True,  # Auto white balance
                "AeEnable": True,   # Auto exposure
                "NoiseReductionMode": controls.draft.NoiseReductionModeEnum.HighQuality
            })
            
            logger.info(f"Pi Camera initialized with resolution {self.resolution}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to initialize Pi Camera: {e}")
            return False
    
    def start_capture(self):
        """Start the camera and begin capturing frames"""
        if self.capturing:
            logger.info("Camera already running")
            return
            
        logger.info("Starting camera capture")
        self.capturing = True
        self.camera_thread = threading.Thread(target=self._capture_loop)
        self.camera_thread.daemon = True
        self.camera_thread.start()
    
    def stop_capture(self):
        """Stop the camera capture"""
        if not self.capturing:
            return
            
        logger.info("Stopping camera capture")
        self.capturing = False
        
        # Stop any active recording
        self._stop_recording()
        
        if self.camera_thread:
            self.camera_thread.join(timeout=2)
            self.camera_thread = None
    
    def _capture_loop(self):
        """Background thread that captures frames from the camera"""
        logger.info("Camera capture thread started")
        
        if not self._initialize_picamera():
            self.capturing = False
            return
        
        try:
            # Start the camera
            self.picam.start()
            
            while self.capturing:
                # Capture frame
                frame = self.picam.capture_array()
                
                # Handle rotation if needed
                if self.rotation != 0:
                    if self.rotation == 90:
                        frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)
                    elif self.rotation == 180:
                        frame = cv2.rotate(frame, cv2.ROTATE_180)
                    elif self.rotation == 270:
                        frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)
                
                # The Pi Camera returns RGB, but OpenCV uses BGR
                frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                
                # Update current frame
                with self.frame_lock:
                    self.current_frame = frame.copy()
                    self.last_frame_time = time.time()
                
                # Process frame for security if in security mode
                if self.security_mode:
                    self._process_security_frame()
                
                # If we're recording, write the frame
                if self.recording_active and self.video_writer is not None:
                    self.video_writer.write(frame)
                    
                    # Check if we should stop recording after a timeout (e.g., 30 seconds)
                    if time.time() - self.recording_start_time > 30:
                        self._stop_recording()
                
                # Short sleep to reduce CPU usage but maintain responsiveness
                time.sleep(0.01)
                
        except Exception as e:
            logger.error(f"Error in camera capture: {e}")
        finally:
            # Stop the camera when done
            if self.picam:
                self.picam.stop()
                self.picam.close()
                self.picam = None
            logger.info("Pi Camera stopped and closed")
        
        logger.info("Camera capture thread stopped")
    
    def get_frame(self):
        """Get the most recent frame from the camera"""
        with self.frame_lock:
            if self.current_frame is not None:
                return self.current_frame.copy()
            return None
    
    def detect_faces(self, frame=None):
        """
        Detect faces in the given frame or current frame using MediaPipe
        
        Returns:
            List of dictionaries containing face information:
            [{"x": x, "y": y, "width": w, "height": h, "confidence": conf, "landmarks": {...}}, ...]
        """
        if frame is None:
            frame = self.get_frame()
            
        if frame is None:
            return []
        
        # Convert the BGR image to RGB for MediaPipe
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # Process the frame with MediaPipe face detection
        results = self.face_detection.process(rgb_frame)
        
        # Initialize list to store detections
        face_detections = []
        
        # Check if any faces were detected
        if results.detections:
            h, w, _ = frame.shape
            
            for detection in results.detections:
                # Get bounding box
                bbox = detection.location_data.relative_bounding_box
                
                # Convert relative coordinates to absolute
                x = int(bbox.xmin * w)
                y = int(bbox.ymin * h)
                width = int(bbox.width * w)
                height = int(bbox.height * h)
                
                # Add landmarks
                landmarks = {}
                for idx, landmark in enumerate(detection.location_data.relative_keypoints):
                    # Convert landmarks to pixel coordinates
                    landmarks[f"point_{idx}"] = {
                        "x": int(landmark.x * w),
                        "y": int(landmark.y * h)
                    }
                
                face_detections.append({
                    "x": x,
                    "y": y,
                    "width": width,
                    "height": height,
                    "confidence": detection.score[0],
                    "landmarks": landmarks
                })
                
        return face_detections
    
    def detect_face_mesh(self, frame=None):
        """
        Detect detailed face mesh in the given frame using MediaPipe
        
        Returns:
            List of dictionaries containing face mesh data with 468 landmarks per face
        """
        if frame is None:
            frame = self.get_frame()
            
        if frame is None:
            return []
        
        # Convert the BGR image to RGB for MediaPipe
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # Process the frame with MediaPipe face mesh
        results = self.face_mesh.process(rgb_frame)
        
        # Initialize list to store mesh data
        mesh_results = []
        
        if results.multi_face_landmarks:
            h, w, _ = frame.shape
            
            for face_landmarks in results.multi_face_landmarks:
                # Convert landmarks to pixel coordinates
                landmarks = []
                for idx, landmark in enumerate(face_landmarks.landmark):
                    landmarks.append({
                        "idx": idx,
                        "x": int(landmark.x * w),
                        "y": int(landmark.y * h),
                        "z": landmark.z
                    })
                
                # Get face bounding box from landmarks
                x_coords = [lm["x"] for lm in landmarks]
                y_coords = [lm["y"] for lm in landmarks]
                
                x = min(x_coords)
                y = min(y_coords)
                width = max(x_coords) - x
                height = max(y_coords) - y
                
                mesh_results.append({
                    "x": x,
                    "y": y,
                    "width": width,
                    "height": height,
                    "landmarks": landmarks
                })
                
        return mesh_results
    
    def take_photo(self, filename=None):
        """
        Take a high-resolution photo
        
        Args:
            filename: Optional filename to save the photo, if None, a timestamp will be used
            
        Returns:
            Path to saved image file
        """
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"photo_{timestamp}.jpg"
        
        # Get current frame
        frame = self.get_frame()
        
        if frame is not None:
            # Save the image
            cv2.imwrite(filename, frame)
            logger.info(f"Photo saved: {filename}")
            return filename
        
        logger.error("Failed to take photo: No frame available")
        return None
    
    def set_security_mode(self, enabled):
        """Enable or disable security mode which uses motion detection"""
        self.security_mode = enabled
        logger.info(f"Security mode {'enabled' if enabled else 'disabled'}")
        
        # When enabling security mode, reset the last frame
        if enabled and self.current_frame is not None:
            with self.frame_lock:
                self.last_frame = self.current_frame.copy()
    
    def _process_security_frame(self):
        """Process the current frame for security purposes using motion detection"""
        if self.last_frame is None:
            with self.frame_lock:
                if self.current_frame is not None:
                    self.last_frame = self.current_frame.copy()
            return
        
        with self.frame_lock:
            if self.current_frame is None:
                return
            
            # Convert frames to grayscale for motion detection
            current_gray = cv2.cvtColor(self.current_frame, cv2.COLOR_BGR2GRAY)
            last_gray = cv2.cvtColor(self.last_frame, cv2.COLOR_BGR2GRAY)
            
            # Calculate absolute difference between current and previous frame
            frame_diff = cv2.absdiff(current_gray, last_gray)
            
            # Apply threshold to highlight differences
            _, thresh = cv2.threshold(frame_diff, 25, 255, cv2.THRESH_BINARY)
            
            # Dilate threshold image to fill in holes
            kernel = np.ones((5, 5), np.uint8)
            thresh = cv2.dilate(thresh, kernel, iterations=2)
            
            # Find contours of movement regions
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # Check if significant motion is detected
            significant_motion = False
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > self.motion_threshold:
                    significant_motion = True
                    break
            
            # If significant motion is detected, record security event
            if significant_motion:
                logger.info("Motion detected in security mode")
                self._record_security_event()
            
            # Update last_frame for next comparison
            self.last_frame = self.current_frame.copy()
    
    def _record_security_event(self):
        """Record a security event when motion is detected"""
        event_time = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # If not already recording, start a new recording
        if not self.recording_active:
            self._start_recording(event_time)
        
        # Check if faces are present in the frame
        faces = self.detect_faces()
        face_detected = len(faces) > 0
        
        # Also save current frame as an image
        img_filename = f"{self.recordings_dir}/security_event_{event_time}.jpg"
        if self.current_frame is not None:
            cv2.imwrite(img_filename, self.current_frame)
            logger.info(f"Security event image saved: {img_filename}")
            
        # Log the event with additional information
        log_filename = f"{self.recordings_dir}/security_event_{event_time}.txt"
        with open(log_filename, "w") as f:
            event_details = {
                "timestamp": datetime.now().isoformat(),
                "face_detected": face_detected,
                "num_faces": len(faces) if face_detected else 0,
                "image_file": img_filename,
                "recording_filename": f"security_video_{event_time}.mp4" if self.recording_active else None
            }
            # Convert event_details to string and write to file
            f.write(str(event_details))
            
        logger.info(f"Security event recorded: {log_filename}")
        return log_filename
    
    def _start_recording(self, timestamp):
        """Start recording video when motion is detected"""
        if self.recording_active:
            return
            
        video_filename = f"{self.recordings_dir}/security_video_{timestamp}.mp4"
        
        # Define the codec and create VideoWriter object
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or 'XVID'
        
        if self.current_frame is not None:
            h, w = self.current_frame.shape[:2]
            self.video_writer = cv2.VideoWriter(
                video_filename, 
                fourcc, 
                10.0,  # FPS
                (w, h)
            )
            
            self.recording_active = True
            self.recording_start_time = time.time()
            logger.info(f"Started security recording: {video_filename}")
    
    def _stop_recording(self):
        """Stop the current video recording"""
        if not self.recording_active:
            return
            
        if self.video_writer:
            self.video_writer.release()
            self.video_writer = None
            
        duration = time.time() - self.recording_start_time
        logger.info(f"Stopped security recording after {duration:.2f} seconds")
        self.recording_active = False
        
    def adjust_brightness(self, brightness):
        """
        Adjust camera brightness
        
        Args:
            brightness: Value between 0 and 100
        """
        if self.picam:
            # Map 0-100 range to the actual range used by Pi Camera
            # The actual range is -1.0 to 1.0
            brightness_value = (brightness / 50.0) - 1.0
            self.picam.set_controls({"Brightness": brightness_value})
            logger.info(f"Camera brightness set to {brightness}")
    
    def set_night_mode(self, enabled):
        """
        Enable or disable night mode for better low-light performance
        
        Args:
            enabled: Boolean to enable/disable night mode
        """
        if not self.picam:
            logger.warning("Cannot set night mode: Camera not initialized")
            return
            
        if enabled:
            # Settings for night mode
            self.picam.set_controls({
                "AwbEnable": False,  # Manual white balance
                "ColourGains": (1.5, 1.5),  # Red and blue gain for night
                "ExposureTime": 66666,  # Longer exposure (in Î¼s)
                "AnalogueGain": 8.0,  # Increase gain (more sensitive but noisier)
                "NoiseReductionMode": controls.draft.NoiseReductionModeEnum.HighQuality
            })
            logger.info("Night mode enabled")
        else:
            # Reset to default settings
            self.picam.set_controls({
                "AwbEnable": True,  # Auto white balance
                "AeEnable": True,   # Auto exposure
                "AnalogueGain": 1.0,
                "NoiseReductionMode": controls.draft.NoiseReductionModeEnum.Standard
            })
            logger.info("Night mode disabled (normal mode)")
    
    def get_video_capture(self):
        """
        Return None to indicate that direct OpenCV capture should not be used.
        Instead, security_mode should use the get_frame() method.
        """
        return None